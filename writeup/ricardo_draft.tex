% Use the following line _only_ if you're still using LaTeX 2.09.
%\documentstyle[icml2017,epsf,natbib]{article}
% If you rely on Latex2e packages, like most moden people use this:
\documentclass{article}

% use Times
\usepackage{times}
% For figures
\usepackage{graphicx} % more modern
%\usepackage{epsfig} % less modern
\usepackage{subfigure} 

% For citations
\usepackage[sort&compress]{natbib}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsthm,amssymb,amsopn,amsmath}

% As of 2011, we use the hyperref package to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{icml2017} with
% \usepackage[nohyperref]{icml2017} above.
\usepackage{hyperref}

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% switched from icml2017 -> arxiv to remove copyright notice
\usepackage[accepted]{arxiv} 

% Employ the following version of the ``usepackage'' statement for
% submitting the draft version of the paper for review.  This will set
% the note in the first column to ``Under review.  Do not distribute.''
%\usepackage{icml2017} 

% Employ this version of the ``usepackage'' statement after the paper has
% been accepted, when creating the final version.  This will set the
% note in the first column to ``Proceedings of the...''
%\usepackage[accepted]{icml2017}
\newtheorem{assumption}{Assumption}
\newtheorem{define}{Definition}
\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{coro}{Corollary}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Counterfactual Fairness}

\begin{document} 

\twocolumn[
\icmltitle{Counterfactual Fairness}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2017
% package.

% list of affiliations. the first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% you can specify symbols, otherwise they are numbered in order
% ideally, you should not use this facility. affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Matt J. Kusner}{equal,ati,ww}
\icmlauthor{Joshua Loftus}{equal,ati,cam}
\icmlauthor{Chris Russell}{equal,ati,ed}
\icmlauthor{Ricardo Silva}{ati,ucl}
%\icmlauthor{Iaesut Saoeu}{ed}
\end{icmlauthorlist}

\icmlaffiliation{ati}{Alan Turing Institute}
\icmlaffiliation{ww}{University of Warwick}
\icmlaffiliation{cam}{University of Cambridge}
\icmlaffiliation{ed}{University of Edinburgh}
\icmlaffiliation{ucl}{University College London}

\icmlcorrespondingauthor{}{mkusner@turing.ac.uk}
\icmlcorrespondingauthor{}{jloftus@turing.ac.uk}
\icmlcorrespondingauthor{}{crussell@turing.ac.uk}
\icmlcorrespondingauthor{}{ricardo.silva@ucl.ac.uk}
% You may provide any keywords that you 
% find helpful for describing your paper; these are used to populate 
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Causality,Counterfactual,Fairness}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\textsuperscript{*}Equal contribution, author order decided randomly}
%\icmlEqualContribution}
%%\icmlEqualContribution} % otherwise use the standard text.
%\footnotetext{hi}

\begin{abstract} 
% fairness is important
  Machine learning has matured to the point to where it is now being considered to
  automate decisions in loan lending, employee hiring, and predictive policing.
  In many of these scenarios however, previous decisions have been made that are unfairly biased
  against certain subpopulations (e.g., those of a particular race,
  gender, or sexual orientation).  Because this past data is often
  biased, machine learning predictors must account for this to avoid perpetuating
  discriminatory practices (or indicentally making new ones).  In this paper, we develop a
  framework for modeling fairness in any dataset using tools from
  counterfactual inference. We propose a definition called
  \emph{counterfactual fairness} that captures the intuition
  that a decision is fair towards an individual, if it gives the same
  predictions in (a) in the observed world and (b) a world where the
  individual had always belonged to a different demographic group,
  other background causes of the outcome being equal. We demonstrate 
  our framework on two real-world problems: fair
  prediction of law school success, and fair modeling of an
  individual's criminality in policing data.
\end{abstract} 

\section{Introduction}
\label{introduction}
\input{intro}

\section{Fairness}
\label{sec:related}
\input{related}

\section{Causal Models and Counterfactuals}
\label{background}
\input{background}

\section{Counterfactual Fairness}
\label{sec:count_fair}
\input{fairness}


\section{Methods and Assessment}
\label{sec:methods}
\input{methods}

\section{Experiments}
\label{sec:experiments}
\input{experiments}

\section{Conclusion}
\label{sec:conclusion}
We have presented a new model of fairness we refer to as {\em counterfactual fairness}. It allows us to propose fair
algorithms that, rather than simply ignoring protected attributes, are
able to take into account the different social biases
that may arise towards individuals of a particular race, gender, or
sexuality and compensate for these biases effectively. We
experimentally contrasted our approach with previous unfair
approaches and show that our explicit causal models capture these
social biases and make clear the implicit trade-off between
prediction accuracy and fairness in an unfair world. We propose that fairness should be regulated by explicitly modeling the causal structure of the world. Criteria based purely on probabilistic independence cannot satisfy this and are unable to address \emph{how} unfairness is occurring in the task at hand. By providing such causal tools for addressing fairness questions we hope we can provide practitioners with customized techniques for solving a wide array of fair modeling problems.

\bibliography{rbas,bibliography}
\bibliographystyle{icml2017}

\end{document} 


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was
% created by Lise Getoor and Tobias Scheffer, it was slightly modified  
% from the 2010 version by Thorsten Joachims & Johannes Fuernkranz, 
% slightly modified from the 2009 version by Kiri Wagstaff and 
% Sam Roweis's 2008 version, which is slightly modified from 
% Prasad Tadepalli's 2007 version which is a lightly 
% changed version of the previous year's version by Andrew Moore, 
% which was in turn edited from those of Kristian Kersting and 
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.  

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "ricardo_draft"
%%% End:
