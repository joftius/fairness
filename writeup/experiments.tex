% !TEX root=ricardo_draft.tex
% In this section we evaluate our framework for modeling fairness.
We illustrate our approach on a practical problem that requires
fairness, the \emph{prediction of success in law school}. A second
problem, \emph{separating actual and perceived criminality in police
  stops}, is described in the Supplementary Material. Following closely the
usual framework for assessing causal models in the machine learning
literature, the goal of this experiment is to quantify how our
algorithm behaves with finite sample sizes while assuming ground truth compatible
with a synthetic model.

\noindent {\bf Problem definition: Law school success}

% From 1991 to 1996
The Law School Admission Council
conducted a survey across 163 law
schools in the United States \cite{wightman1998lsac}. % The survey was
% designed to assess `the law school experience of minority students, as
% well as their ultimate entry into the profession'.
It contains information on 21,790 law students such as their entrance
exam scores (LSAT), their grade-point average (GPA) collected prior to
law school, and their first year average grade (FYA).
%, and following Law
%School i.e. whether students passed the final examination, the `bar
%exam' (P)).

Given this data, a school may wish to predict if an applicant will
have a high FYA.
% from information about their academic performance
% before law school.
The school would also like to make sure these
predictions are not biased by an individual's race and sex. However,
the LSAT, GPA, and FYA scores, may be biased due to social factors. % Our approach will use variables that are
% counterfactually fair for prediction.
We compare our framework with two unfair baselines: 1. \textbf{Full}:
the standard technique of using all features, including sensitive
features such as race and sex to make predictions;
2. \textbf{Unaware}: fairness through unawareness, where we do not use
race and sex as features. For comparison, we generate predictors $\hat
Y$ for all models using logistic regression.


\paragraph{Fair prediction.}
As described in Section~\ref{sec:limit-guide-model}, there are three
ways in which we can model a counterfactually fair predictor of
FYA. Level 1 uses any features which are not descendants of race and
sex for prediction. Level 2 models latent `fair' variables which are
parents of observed variables. These variables are independent of both
race and sex. Level 3 models the data using an additive error model,
and uses the independent error terms to make predictions. These models
make increasingly strong assumptions corresponding to increased
predictive power. We split the dataset 80/20 into a train/test set,
preserving label balance, to evaluate the models.

As we believe LSAT, GPA, and FYA are all biased by race and sex, we
cannot use any observed features to construct a counterfactually fair
predictor as described in Level 1. % Instead we would need to resort to a
% constant predictor% , such as the mean of FYA over the training set
% . % As this model is trivial we do not consider it. 

In Level 2, we postulate that a latent variable: a student's
\textbf{knowledge} (K), affects GPA, LSAT, and FYA scores. The causal
graph corresponding to this model is shown in
Figure~\ref{figure.law_school}, (\textbf{Level 2}). This is a
short-hand for the distributions:
% NIPS VERSION BELOW
% \[
% \begin{array}{cc}
%   \mbox{GPA} \sim {\cal N}(b_{G} + w_{G}^K K + w_{G}^R R + w_{G}^S S, \sigma_{G}),&  \hspace{0.2in}
%   \mbox{FYA} \sim {\cal N}(w_{F}^K K + w_{F}^R R + w_{F}^S S, 1),\\
%   \mbox{LSAT} \sim \textrm{Poisson}(\exp(b_{L} + w_{L}^K K + w_{L}^R R + w_{L}^S S)),& \hspace{0.2in}
%   \mbox{K} \sim {\cal N}(0,1)
% \end{array}
% \]
% ARXIV VERSION BELOW
\[
\begin{array}{ll}
  &\mbox{GPA} \sim {\cal N}(b_{G} + w_{G}^K K + w_{G}^R R + w_{G}^S S, \sigma_{G}),
  \;\;\mbox{FYA} \sim {\cal N}(w_{F}^K K + w_{F}^R R + w_{F}^S S, 1),\\
  &\mbox{LSAT} \sim \textrm{Poisson}(\exp(b_{L} + w_{L}^K K + w_{L}^R R + w_{L}^S S)), 
  \;\;\mbox{K} \sim {\cal N}(0,1)
\end{array}
\]
%\begin{align}
%\mbox{GPA} &\sim {\cal N}(b_{G} + w_{G}^K K + w_{G}^R R + w_{G}^S S, \sigma_{G}),
%\mbox{LSAT} &\sim \textrm{Poisson}(\exp(b_{L} + w_{L}^K K + w_{L}^R R + w_{L}^S S)) \nonumber \\
%\mbox{FYA} &\sim {\cal N}(w_{F}^K K + w_{F}^R R + w_{F}^S S, 1), 
%K &\sim {\cal N}(0,1) \nonumber
%\end{align}
% As FYA is already standardized to have mean $0$ and standard
% deviation $1$ we do not learn bias and standard deviation terms.
We perform inference on this model using an observed training set to
estimate the posterior distribution of $K$. We use the probabilistic
programming language Stan \cite{rstan} to learn $K$. We call the
predictor constructed using $K$, \textbf{Fair $K$}.


\begin{figure}[th]
  \begin{tabular}{p{0.5\columnwidth}p{0.5\columnwidth}}
    \centerline{\includegraphics[width=0.5\columnwidth]{law_school_model}}
    &
      \centerline{\includegraphics[width=0.5\columnwidth]{counterfactual}}
  \end{tabular}
  \caption{{\bf Left:} A causal model for the problem of predicting law school success fairly.\label{figure.law_school}
  {\bf Right:} Density plots of predicted $\mbox{FYA}_a$ and $\mbox{FYA}_{a'}$.\label{figure.counterfactual}
}
\end{figure}

\begin{table}
\centering
\caption{Prediction results using logistic regression. Note that we
  must sacrifice a small amount of accuracy to ensuring
  counterfactually fair prediction (Fair $K$, Fair Add), versus the
  models that use unfair features: GPA, LSAT, race, sex (Full,
  Unaware).} \label{table.pred_law}
\begin{tabular}{ccccc} 
\hline
 &  {\bf Full} & {\bf Unaware} & {\bf Fair $K$} & {\bf Fair Add} \\
\hline
RMSE & 0.873 & 0.894 & 0.929 & 0.918 \\
%\bf{Method} & %\multicolumn{2}{c}{\bf Full} & \multicolumn{2}{c}{\bf Unaware} & \multicolumn{2}{c}{\bf Fair L2} & \multicolumn{2}{c}{\bf Fair L3} \\
\hline
\end{tabular}
\end{table}

In Level 3, we model GPA, LSAT, and FYA as continuous variables with additive error terms independent of
race and sex (that may in turn be correlated with one-another). This model is shown in
Figure~\ref{figure.law_school}, (\textbf{Level 3}), and is expressed by: % the equations:
\begin{align}
\mbox{GPA} &= b_{G} + w_{G}^R R + w_{G}^S S + \epsilon_G, \;\; \epsilon_G \sim p(\epsilon_G) \nonumber \\
\mbox{LSAT} &= b_{L} + w_{L}^R R + w_{L}^S S + \epsilon_L, \;\; \epsilon_L \sim p(\epsilon_L) \nonumber \\
\mbox{FYA} &= b_{F} + w_{F}^R R + w_{F}^S S + \epsilon_F, \;\; \epsilon_F \sim p(\epsilon_F) \nonumber
\end{align}
We estimate the error terms $\epsilon_G,\epsilon_L$ by first fitting
two models that each use race and sex to individually predict GPA and
LSAT. We then compute the residuals of each model (e.g., $\epsilon_G
\!=\! \mbox{GPA} \!-\! \hat{Y}_{\scriptsize\mbox{GPA}}(R,S)$). We use
these residual estimates of $\epsilon_G,\epsilon_L$ to predict FYA. We
call this \emph{Fair Add}.


% impacts these features.

% We propose to model the law school data as shown in
% Figure~\ref{figure.law_school}. We suspect that variables race and sex
% affect student performance (e.g. GPA, LSAT, and FYA) due to factors
% such as cultural norms, which assume that individuals of a certain
% race or sex are `better suited' to be lawyers. Such beliefs could
% adversely impact students who do not fit these norms. Instead we would
% like to model the latent \emph{knowledge} (K) of a student, which also
% impacts these features. 
% We can then construct a predictor that
% predicts FYA fairly using knowledge. It is easy to show that such a predictor
% is counterfactually fair, whereas a predictor that uses features GPA and
% LSAT is not (in this case even including race and sex as
% features cannot correct this, as can be done in the linear case). The
% causal 
 %; %3. \textbf{Variational Fair Autoencoder (VFAE)} \cite{louizos2015variational}, a recent approach that works to learn a fair representation of the original data.
% compute counterfactuals for both race and sex

\paragraph{Accuracy.}
We compare the RMSE achieved by logistic regression for each of the
models on the test set in Table~\ref{table.pred_law}.  The
\textbf{Full} model achieves the lowest RMSE as it uses race and sex
to more accurately reconstruct FYA. Note that in this case, this model
is not fair even if the data was generated by one of the models shown
in Figure~\ref{figure.law_school} as it corresponds to Scenario 3. The
(also unfair) \textbf{Unaware} model still uses the unfair variables
GPA and LSAT, but because it does not use race and sex it cannot match
the RMSE of the \textbf{Full} model. As our models satisfy
counterfactual fairness, they trade off some accuracy. Our first model
\textbf{Fair $K$} uses weaker assumptions and thus the RMSE is
highest. Using the Level 3 assumptions, as in \textbf{Fair Add} we
produce a counterfactually fair model that trades
slightly stronger assumptions for lower RMSE.


\paragraph{Counterfactual fairness.}
We would like to empirically test whether the baseline methods are
counterfactually fair. To do so we will assume the true model of the
world is given by Figure~\ref{figure.law_school}, (\textbf{Level
  2}). We can fit the parameters of this model using the observed data
and evaluate counterfactual fairness by sampling from
it. Specifically, we will generate samples from the model given either
the observed race and sex, or \emph{counterfactual} race and sex
variables. We will fit models to both the original and counterfactual
sampled data and plot how the distribution of predicted FYA changes
for both baseline models. Figure~\ref{figure.counterfactual} shows
this, where each row corresponds to a baseline predictor and each
column corresponds to the counterfactual change. In each plot, the blue
distribution is density of predicted FYA for the original data and the
red distribution is this density for the counterfactual data. If a
model is counterfactually fair we would expect these distributions to
lie exactly on top of each other. Instead, we note that the
\textbf{Full} model exhibits counterfactual unfairness for all
counterfactuals except sex. We see a similar trend for the
\textbf{Unaware} model, although it is closer to being
counterfactually fair. To see why these models seem to be fair
w.r.t. to sex we can look at weights of the DAG which generates the
counterfactual data. Specifically the DAG weights from (male,female)
to GPA are ($0.93$,$1.06$) and from (male,female) to LSAT are
($1.1$,$1.1$). Thus, these models are fair w.r.t. to sex simply
because of a very weak causal link between sex and GPA/LSAT.

% here describe what we see

% maybe sample from model and check it out
%\paragraph{Model validity.}
 

% TODO rank top 10 students by ability or by other score in law_school.py which only considers observed features


% \begin{table}[t]
% \vspace{-2ex}
% \caption{}
% \vspace{-3ex}
% \label{table.pred_law}
% \begin{center}
% \resizebox{\columnwidth}{!}
% {
% \begin{sc}
% \footnotesize
% \begin{tabular}{c|c|c|c}
% \hline
% %\multicolumn{5}{c}{\textbf{Lower Bounds}}\\
% \hline
% & full & unaware  & fair l2 & fair l3 \\
% \hline
% RMSE & 0.873 & 0.894 & 0.929 & 0.918 \\ \hline
% \end{tabular}
% \end{sc}
% }
% \end{center}
% \vspace{-4ex}
% \end{table}

%{lr@{$\pm$}lr@{$\pm$}lr@{$\pm$}l}

%\subsection{Model criticism}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "ricardo_draft"
%%% End:
