% !TEX root=ricardo_draft.tex
% binary classification
There has been a wealth of recent work towards fair machine learning algorithms. In large part, these methods have focussed (and reasonably so) on binary classification with a binary sensitive attributes (CITE). A concurrent goal of these works was to construct a working definition of fairness (or unfairness) that could be evaluated and optimized. These include fairness through unawareness/disparate treatment (cite: gummadi), demographic parity/disparate impact (CITE: learning fair classifiers), individual fairness (CITE: dwork, zemel, rawls), equality of opportunity/disparate mistreatment (CITE: hardt, gummadi)

A variety of algorithmic approaches to achieving fairness have been proposed. Most similar to our work is by (CITE: zemel)




% finding a latent U

% orthogonal features

